# Interpretabilidade: Pixel Flipping & Region Perturbation

## Descrição do Projeto
Este projeto tem como objetivo explorar a **interpretabilidade de modelos de machine learning** aplicados à classificação de imagens de cães e gatos. Para isso, implementamos e avaliamos **métodos de interpretabilidade** usando duas métricas quantitativas: **Pixel Flipping** e **Region Perturbation**.

O trabalho permite:
- Compreender quais regiões da imagem influenciam mais as previsões do modelo.
- Comparar diferentes métodos de explicação (Grad-CAM, Saliency Maps, LIME, SHAP, Guided Backpropagation).
- Avaliar quantitativamente a qualidade das explicações.